from bs4.element import PageElement
import requests
from bs4 import BeautifulSoup
import csv

URL =  "https://4pda.to/"
HEADERS = {
    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'user-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15'
}

def get_html(url, params=''):
    r = requests.get(url, headers=HEADERS, params=params)
    return r

def get_content(html):
    soup = BeautifulSoup(html, 'html.parser')
    items = soup.find_all('article', class_="post CoCxZK")
    news = []
    for item in items:
        news.append({'headers' : item.find('div', class_='description').find('span').get_text(),
                    'link' : item.find('div', class_='description').find('a').get('href')
        })
    return news

def parser():
    PAGINATION = input('Сколько страниц нужно проверить?')
    PAGINATION = int(PAGINATION)
    html = get_html(URL)
    news = []
    for page in range(1, PAGINATION):
        html = get_html(URL, params={'page':page})
        news.extend(get_content(html.text))
    return news
    
def NEWS():
    number = 0
    for i in parser():
        print('{}. {}\n{}'.format(str(number), i['headers'], i['link']))
        number +=1

NEWS()


